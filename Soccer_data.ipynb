{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soccer data\n",
    "\n",
    "Two soccer data sets pulled from kaggle.\n",
    "\n",
    "CSV soccer data set: https://www.kaggle.com/secareanualin/football-events\n",
    "\n",
    "SQLITE soccer data set: https://www.kaggle.com/hugomathien/soccer \n",
    "\n",
    "## CSV soccer data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dictionary.txt and make a nested dictionary \n",
    "dicts = ['event_type','event_type2','side','shot_place','shot_outcome','location','bodypart','assist_method','situation']\n",
    "\n",
    "file = open('Resources/dictionary.txt')\n",
    "f = csv.reader(file,delimiter='\\t')\n",
    "\n",
    "event = {} \n",
    "\n",
    "key0 = None \n",
    "\n",
    "for row in f:\n",
    "    if(len(row)>0):\n",
    "        if(row[0] in dicts):\n",
    "            key = row[0]\n",
    "            event[key] = {}\n",
    "        if(len(row)>1):\n",
    "            event[key][int(row[0])] = row[1]\n",
    "\n",
    "file.close()\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import events CSV\n",
    "data = pd.read_csv(\"Resources/events.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "# Use events dictionary to replace values in the data df \n",
    "data['event_type'] = data['event_type'].map(event['event_type'])\n",
    "data['event_type2'] = data['event_type2'].map(event['event_type2'])\n",
    "data['side'] = data['side'].map(event['side'])\n",
    "data['shot_place'] = data['shot_place'].map(event['shot_place'])\n",
    "data['shot_outcome'] = data['shot_outcome'].map(event['shot_outcome'])\n",
    "data['location'] = data['location'].map(event['location'])\n",
    "data['bodypart'] = data['bodypart'].map(event['bodypart'])\n",
    "data['assist_method'] = data['assist_method'].map(event['assist_method'])\n",
    "data['situation'] = data['situation'].map(event['situation'])\n",
    "\n",
    "# Capitalize names\n",
    "data['player'] = data['player'].str.title()\n",
    "data['player2'] = data['player2'].str.title()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ginf CSV\n",
    "metadata = pd.read_csv(\"Resources/ginf.csv\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLITE soccer data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create engine to database.sqlite\n",
    "engine = create_engine(\"sqlite:///Resources/database.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine.execute('SELECT * FROM Country')\n",
    "keys = engine.execute('SELECT * FROM Country').keys()\n",
    "\n",
    "data = []\n",
    "column = []\n",
    "\n",
    "for row in results:\n",
    "    data.append(row)\n",
    "    \n",
    "for row in keys:\n",
    "    column.append(row)\n",
    "    \n",
    "country = pd.DataFrame(data, columns=column)\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine.execute('SELECT * FROM League')\n",
    "keys = engine.execute('SELECT * FROM League').keys()\n",
    "\n",
    "data = []\n",
    "column = []\n",
    "\n",
    "for row in results:\n",
    "    data.append(row)\n",
    "    \n",
    "for row in keys:\n",
    "    column.append(row)\n",
    "    \n",
    "league = pd.DataFrame(data, columns=column)\n",
    "league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine.execute('SELECT * FROM Match')\n",
    "keys = engine.execute('SELECT * FROM Match').keys()\n",
    "\n",
    "data = []\n",
    "column = []\n",
    "\n",
    "for row in results:\n",
    "    data.append(row)\n",
    "    \n",
    "for row in keys:\n",
    "    column.append(row)\n",
    "    \n",
    "match = pd.DataFrame(data, columns=column)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning, getting rid of the hours in date column\n",
    "match['date'] = match['date'].str.split(' ',expand=True)[0]\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "match = match.drop_duplicates(subset=['match_api_id'], keep='first')\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine.execute('SELECT * FROM Player')\n",
    "keys = engine.execute('SELECT * FROM Player').keys()\n",
    "\n",
    "data = []\n",
    "column = []\n",
    "\n",
    "for row in results:\n",
    "    data.append(row)\n",
    "    \n",
    "for row in keys:\n",
    "    column.append(row)\n",
    "    \n",
    "player = pd.DataFrame(data, columns=column)\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning, getting rid of the hours in birthday column\n",
    "player['birthday'] = player['birthday'].str.split(' ',expand=True)[0]\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "player = player.drop_duplicates(subset=['player_name'], keep='first')\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine.execute('SELECT * FROM Team')\n",
    "keys = engine.execute('SELECT * FROM Team').keys()\n",
    "\n",
    "data = []\n",
    "column = []\n",
    "\n",
    "for row in results:\n",
    "    data.append(row)\n",
    "    \n",
    "for row in keys:\n",
    "    column.append(row)\n",
    "    \n",
    "team = pd.DataFrame(data, columns=column)\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "team = team.drop_duplicates(subset=['team_long_name'], keep='first')\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine.execute('SELECT * FROM Player_Attributes')\n",
    "keys = engine.execute('SELECT * FROM Player_Attributes').keys()\n",
    "\n",
    "data = []\n",
    "column = []\n",
    "\n",
    "for row in results:\n",
    "    data.append(row)\n",
    "    \n",
    "for row in keys:\n",
    "    column.append(row)\n",
    "    \n",
    "player_attributes = pd.DataFrame(data, columns=column)\n",
    "player_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning, getting rid of the hours in date column\n",
    "player_attributes['date'] = player_attributes['date'].str.split(' ',expand=True)[0]\n",
    "player_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine.execute('SELECT * FROM Team_Attributes')\n",
    "keys = engine.execute('SELECT * FROM Team_Attributes').keys()\n",
    "\n",
    "data = []\n",
    "column = []\n",
    "\n",
    "for row in results:\n",
    "    data.append(row)\n",
    "    \n",
    "for row in keys:\n",
    "    column.append(row)\n",
    "    \n",
    "team_attributes = pd.DataFrame(data, columns=column)\n",
    "team_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning, getting rid of the hours in date column\n",
    "team_attributes['date'] = team_attributes['date'].str.split(' ',expand=True)[0]\n",
    "team_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unifiying both data sets\n",
    "\n",
    "Each data set has a hard time to find a link in between each other, the goal of this section is to create auxiliar dataframes that can easily connect both data sets. This will be done through teams for the metadata set and players for the data set.\n",
    "\n",
    "## Teams table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get teams and ids from the team dataframe\n",
    "team_id = team['team_api_id'].tolist()\n",
    "team_name = team['team_long_name'].tolist()\n",
    "\n",
    "# Insert both lists into two nested lists for easy indexing\n",
    "team_info = [team_id,team_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure there are no duplicates, both list's length have to be equal\n",
    "print(len(team_id))\n",
    "print(len(team_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique teams from the metadata dataframe\n",
    "metadata_htname = metadata['ht'].unique().tolist()\n",
    "metadata_atname = metadata['at'].unique().tolist()\n",
    "\n",
    "# Find common teams in both data sets\n",
    "unique_teams = list(set(metadata_htname + metadata_atname))\n",
    "common_teams = list(set(unique_teams) & set(team_name))\n",
    "\n",
    "# Create a list with two nested lists\n",
    "common_teams_data = []\n",
    "common_teams_data.append(common_teams)\n",
    "common_teams_data.append([None] * len(common_teams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill out the list with the ids of the teams in common\n",
    "for x in range(len(common_teams_data[0])):\n",
    "    for y in range(len(team_info[1])) :\n",
    "        if common_teams_data[0][x] == team_info[1][y]:\n",
    "            common_teams_data[1][x] = team_info[0][y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create auxiliar dataframe\n",
    "common_teams_df = pd.DataFrame(columns=['team_id','team'])\n",
    "common_teams_df['team_id'] = common_teams_data[1]\n",
    "common_teams_df['team'] = common_teams_data[0]\n",
    "\n",
    "common_teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that the team and id match\n",
    "team.loc[team['team_long_name'] == 'Liverpool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that the team and id match\n",
    "team.loc[team['team_api_id'] == 9804]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Players table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get players and ids from the team dataframe\n",
    "player_name = player['player_name'].tolist()\n",
    "player_id = player['player_api_id'].tolist()\n",
    "\n",
    "# Insert both lists into two nested lists for easy indexing\n",
    "player_info = [player_id,player_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure there are no duplicates, both list's length have to be equal\n",
    "print(len(player_id))\n",
    "print(len(player_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique players from data dataframe\n",
    "data_player1 = data['player'].unique().tolist()\n",
    "data_player2 = data['player2'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find unique players from both lists\n",
    "unique_players = list(set(data_player1 + data_player2))\n",
    "common_players = list(set(unique_players) & set(player_name))\n",
    "\n",
    "common_players_info = []\n",
    "common_players_info.append(common_players)\n",
    "common_players_info.append([None] * len(common_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(common_players_info[0])):\n",
    "    for y in range(len(player_info[1])):\n",
    "        if common_players_info[0][x] == player_info[1][y]:\n",
    "            common_players_info[1][x] = player_info[0][y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create auxiliar dataframe\n",
    "common_players_data = pd.DataFrame(columns=['player_id','player'])\n",
    "common_players_data['player_id'] = common_players_info[1]\n",
    "common_players_data['player'] = common_players_info[0]\n",
    "\n",
    "common_players_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.loc[player['player_api_id'] == 127894]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.loc[player['player_api_id'] == 129763]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting tables into Postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# dotenv adds .env variables to the environment\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables\n",
    "load_dotenv()\n",
    "key = os.environ['KEY']\n",
    "\n",
    "# Create engine and connect to PostgreSQL\n",
    "engine = create_engine('postgresql://postgres:'+key+'@localhost:5432/soccer_data')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables from the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data dataframe into PostgreSQL\n",
    "data.to_sql('event_data', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set id_odsp and id_event as primary keys\n",
    "connection.execute('ALTER TABLE event_data ADD PRIMARY KEY (id_odsp,id_event);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert metadata dataframe into PostgreSQL\n",
    "metadata.to_sql('event', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set id_odsp as primary keys\n",
    "connection.execute('ALTER TABLE event ADD PRIMARY KEY (id_odsp);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.execute('ALTER TABLE event ALTER COLUMN date TYPE DATE USING date::date;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables from the SQLite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert country dataframe into PostgreSQL\n",
    "country.to_sql('country', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set id as primary key\n",
    "connection.execute('ALTER TABLE country ADD PRIMARY KEY (id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert league dataframe into PostgreSQL\n",
    "league.to_sql('league', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set country_id as primary key\n",
    "connection.execute('ALTER TABLE league ADD PRIMARY KEY (country_id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert match dataframe into PostgreSQL\n",
    "match.to_sql('match', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set id as primary key\n",
    "connection.execute('ALTER TABLE match ADD PRIMARY KEY (match_api_id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.execute('ALTER TABLE match ALTER COLUMN date TYPE DATE USING date::date;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert player dataframe into PostgreSQL\n",
    "player.to_sql('player', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set player_api_id and id as primary keys\n",
    "connection.execute('ALTER TABLE player ADD PRIMARY KEY (player_api_id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.execute('ALTER TABLE player ALTER COLUMN birthday TYPE DATE USING birthday::date;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert team dataframe into PostgreSQL\n",
    "team.to_sql('team', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set player_api_id and id as primary keys\n",
    "connection.execute('ALTER TABLE team ADD PRIMARY KEY (team_api_id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert player_attributes dataframe into PostgreSQL\n",
    "player_attributes.to_sql('player_attributes', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set player_api_id and id as primary keys\n",
    "connection.execute('ALTER TABLE player_attributes ADD PRIMARY KEY (id,player_api_id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.execute('ALTER TABLE player_attributes ALTER COLUMN date TYPE DATE USING date::date;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert team_attributes dataframe into PostgreSQL\n",
    "team_attributes.to_sql('team_attributes', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set team_api_id and id as primary keys\n",
    "connection.execute('ALTER TABLE team_attributes ADD PRIMARY KEY (id,team_api_id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.execute('ALTER TABLE team_attributes ALTER COLUMN date TYPE DATE USING date::date;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert common_teams_df dataframe into PostgreSQL\n",
    "common_teams_df.to_sql('common_teams', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set team_id as primary keys\n",
    "connection.execute('ALTER TABLE common_teams ADD PRIMARY KEY (team_id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set team as UNIQUE constraint, isolation level has to be autocommit, more info here: https://docs.sqlalchemy.org/en/14/core/connections.html#sqlalchemy.engine.Connection.execution_options.params.isolation_level\n",
    "connection.execution_options(isolation_level=\"AUTOCOMMIT\").execute('CREATE UNIQUE INDEX CONCURRENTLY unique_team_id ON common_teams (team);')\n",
    "connection.execute('ALTER TABLE common_teams ADD CONSTRAINT unique_team UNIQUE USING INDEX unique_team_id;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert common_teams_df dataframe into PostgreSQL\n",
    "common_players_data.to_sql('common_players', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Set player_id as primary keys\n",
    "connection.execute('ALTER TABLE common_players ADD PRIMARY KEY (player_id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.execute('CREATE UNIQUE INDEX CONCURRENTLY unique_player_id ON common_players (player);')\n",
    "connection.execute('ALTER TABLE common_players ADD CONSTRAINT unique_player UNIQUE USING INDEX unique_player_id;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
